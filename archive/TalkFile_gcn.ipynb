{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7sn3cwqJXBP_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import PandasTools\n",
        "from rdkit.Chem import AllChem\n",
        "import rdkit\n",
        "from rdkit.Chem import Descriptors\n",
        "# from mordred import Calculator, descriptors\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import ChemicalFeatures\n",
        "from rdkit import RDConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gNs4uNKXWnp7"
      },
      "outputs": [],
      "source": [
        "def getMolDescriptors(mol, missingVal=None):\n",
        "    res = {}\n",
        "    for nm,fn in Descriptors._descList:\n",
        "        # some of the descriptor fucntions can throw errors if they fail, catch those here:\n",
        "        try:\n",
        "            val = fn(mol)\n",
        "        except:\n",
        "            # print the error message:\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            # and set the descriptor value to whatever missingVal is\n",
        "            val = missingVal\n",
        "        res[nm] = val\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5msd5hlAXZcn"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('../input/train.csv')\n",
        "train_df['AlogP'] = np.where(pd.isna(train_df['AlogP']), train_df['LogD'], train_df['AlogP'])\n",
        "test_df = pd.read_csv('../input/test.csv')\n",
        "test_df['AlogP'] = np.where(pd.isna(test_df['AlogP']), test_df['LogD'], test_df['LogD'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mw9hlJqQYU2a"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop_duplicates('SMILES', keep=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sxjM7KIaYeII"
      },
      "outputs": [],
      "source": [
        "target_hlm = train_df['HLM']\n",
        "target_mlm = train_df['MLM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LV0EHuBVYrTu"
      },
      "outputs": [],
      "source": [
        "train_df['Molecule'] = train_df['SMILES'].apply(Chem.MolFromSmiles)\n",
        "test_df['Molecule'] = test_df['SMILES'].apply(Chem.MolFromSmiles)\n",
        "train_desc = [getMolDescriptors(m) for m in train_df['Molecule']]\n",
        "test_desc = [getMolDescriptors(m) for m in test_df['Molecule']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c2-8_GggZ5HR"
      },
      "outputs": [],
      "source": [
        "train_desc = pd.DataFrame(train_desc)\n",
        "test_desc = pd.DataFrame(test_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CmXNQ_qMaOtc"
      },
      "outputs": [],
      "source": [
        "null_list = []\n",
        "for col in train_desc.columns:\n",
        "  missing = train_desc[col].isna().any()\n",
        "  if missing == True:\n",
        "    null_list.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LNmq5sqobIAM"
      },
      "outputs": [],
      "source": [
        "train_desc = train_desc.drop(null_list, axis=1)\n",
        "test_desc = test_desc.drop(null_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tyetz61SdVIC"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train_df, train_desc],axis=1).drop(columns=['id','SMILES','Molecule','MLM','HLM','MolWt', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'MolLogP'])\n",
        "test = pd.concat([test_df, test_desc],axis=1).drop(columns=['id','SMILES','Molecule','MolWt', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'MolLogP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3sv733ZXkAvh"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JlJS8ZvGjVos"
      },
      "outputs": [],
      "source": [
        "features = [col for col in train.columns]\n",
        "train[features] = scaler.fit_transform(train[features])\n",
        "test[features] = scaler.transform(test[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tMCE0arUlE3d"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "import dgl.function as fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iebcU2xglL_Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ppAiMCWkk4Tz"
      },
      "outputs": [],
      "source": [
        "ATOM_VOCAB = [\n",
        "\t'C', 'N', 'O', 'S', 'F',\n",
        "\t'H', 'Si', 'P', 'Cl', 'Br',\n",
        "\t'Li', 'Na', 'K', 'Mg', 'Ca',\n",
        "\t'Fe', 'As', 'Al', 'I', 'B',\n",
        "\t'V', 'Tl', 'Sb', 'Sn', 'Ag',\n",
        "\t'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
        "\t'Ge', 'Cu', 'Au', 'Ni', 'Cd',\n",
        "\t'Mn', 'Cr', 'Pt', 'Hg', 'Pb'\n",
        "]\n",
        "def one_of_k_encoding(x, vocab):\n",
        "  if x not in vocab:\n",
        "    print(f\"Not in ATOM_VOCAB: {x}\")\n",
        "    x = vocab[-1]\n",
        "  return list(map(lambda s: float(x==s), vocab))\n",
        "\n",
        "\n",
        "def get_atom_feature(atom):\n",
        "\tatom_feature = one_of_k_encoding(atom.GetSymbol(), ATOM_VOCAB)   #c면 [1,0,0,0,....] n이면[0,1,0,0,0,.....]\n",
        "\tatom_feature += one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) #다리가 몇갠지\n",
        "\tatom_feature += one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4])\n",
        "\tatom_feature += one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n",
        "\tatom_feature += [atom.GetIsAromatic()]\n",
        "\treturn atom_feature\n",
        "\n",
        "def get_bond_feature(bond):\n",
        "  bt = bond.GetBondType()\n",
        "  bond_feature = [\n",
        "      bt == Chem.rdchem.BondType.SINGLE,\n",
        "      bt == Chem.rdchem.BondType.DOUBLE,\n",
        "      bt == Chem.rdchem.BondType.TRIPLE,\n",
        "      bt == Chem.rdchem.BondType.AROMATIC,\n",
        "      bond.GetIsConjugated(),  #결합체인가\n",
        "      bond.IsInRing()           #링안에 있는지\n",
        "  ]\n",
        "  return bond_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OKE1VRMblCGo"
      },
      "outputs": [],
      "source": [
        "def get_molecular_graph(smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  graph = dgl.DGLGraph()\n",
        "\n",
        "  atom_list = mol.GetAtoms()\n",
        "  num_atoms = len(atom_list)\n",
        "  graph.add_nodes(num_atoms)\n",
        "\n",
        "  atom_feature_list = [get_atom_feature(atom) for atom in atom_list]\n",
        "  atom_feature_list = torch.tensor(atom_feature_list, dtype=torch.float64)\n",
        "  graph.ndata['h'] = atom_feature_list\n",
        "\n",
        "  bond_list = mol.GetBonds()\n",
        "  bond_feature_list = []\n",
        "  for bond in bond_list:\n",
        "    bond_feature = get_bond_feature(bond)\n",
        "\n",
        "    src = bond.GetBeginAtom().GetIdx() #엣지 시작점\n",
        "    dst = bond.GetEndAtom().GetIdx()   #끝점\n",
        "\n",
        "    ## DGL 그래프는 방향성이 없어\n",
        "    ## 쌍으로 줘야함\n",
        "    # i --> j\n",
        "    graph.add_edges(src, dst)\n",
        "    bond_feature_list.append(bond_feature)\n",
        "    # j --> i\n",
        "    graph.add_edges(dst, src)\n",
        "    bond_feature_list.append(bond_feature)\n",
        "\n",
        "  bond_feature_list = torch.tensor(bond_feature_list, dtype = torch.float64)\n",
        "  graph.edata['e_ij'] = bond_feature_list\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nh59n-yLyRKz"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "graph() missing 1 required positional argument: 'data'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m smi \u001b[39min\u001b[39;00m train_df[\u001b[39m'\u001b[39m\u001b[39mSMILES\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m   graph \u001b[39m=\u001b[39m get_molecular_graph(smi)\n\u001b[1;32m      4\u001b[0m   graph_list\u001b[39m.\u001b[39mappend(graph)\n",
            "Cell \u001b[0;32mIn[16], line 3\u001b[0m, in \u001b[0;36mget_molecular_graph\u001b[0;34m(smi)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_molecular_graph\u001b[39m(smi):\n\u001b[1;32m      2\u001b[0m   mol \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39mMolFromSmiles(smi)\n\u001b[0;32m----> 3\u001b[0m   graph \u001b[39m=\u001b[39m dgl\u001b[39m.\u001b[39;49mgraph()\n\u001b[1;32m      5\u001b[0m   atom_list \u001b[39m=\u001b[39m mol\u001b[39m.\u001b[39mGetAtoms()\n\u001b[1;32m      6\u001b[0m   num_atoms \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(atom_list)\n",
            "\u001b[0;31mTypeError\u001b[0m: graph() missing 1 required positional argument: 'data'"
          ]
        }
      ],
      "source": [
        "graph_list = []\n",
        "for smi in train_df['SMILES']:\n",
        "  graph = get_molecular_graph(smi)\n",
        "  graph_list.append(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6LwFVVIWsrW"
      },
      "outputs": [],
      "source": [
        "def my_collate_fn(batch):\n",
        "  graph_list=[]\n",
        "  for item in batch:\n",
        "    graph = get_molecular_graph(item[1])\n",
        "    graph_list.append(graph)\n",
        "  graph_list = dgl.batch(graph_list)\n",
        "  features = item[0]\n",
        "  label = item[2]\n",
        "  return torch.tensor(features).float(), graph_list, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baRY_VC5w44H"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KilKegrnxriA"
      },
      "outputs": [],
      "source": [
        "class MolDataset(Dataset):\n",
        "  def __init__(self, df, graph, label=None, test=False):\n",
        "    self.df = df\n",
        "    self.graph = graph\n",
        "    self.label = label\n",
        "    self.test = test\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if not self.test:\n",
        "      return self.df.iloc[idx].values, self.graph[idx], torch.tensor(self.label[idx]).float()\n",
        "    else:\n",
        "      return self.df.iloc[idx].values, self.graph[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BThfa-Gu0Y_Z"
      },
      "outputs": [],
      "source": [
        "hlm_dataset = MolDataset(df = train, graph = train_df['SMILES'], label = target_hlm, test= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxubUBzd0ux7"
      },
      "outputs": [],
      "source": [
        "input_size = hlm_dataset.df.shape[1]  #199\n",
        "graph_nsize = 58#graph.ndata['h'].shape[1]   #58\n",
        "graph_esize = 6#graph.edata['e_ij'].shape[1]   #6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi6s0wfm0w1K"
      },
      "outputs": [],
      "source": [
        "train_hlm_data, valid_hlm_data = train_test_split(hlm_dataset, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l-_XDYC1TZE"
      },
      "outputs": [],
      "source": [
        "train_hlm_loader = DataLoader(dataset=train_hlm_data, batch_size=256, shuffle=True, collate_fn = my_collate_fn)\n",
        "val_hlm_loader = DataLoader(dataset=valid_hlm_data, batch_size=256, shuffle=False, collate_fn = my_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc80kq_w2Vjv"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear1 = nn.Linear(58, 256)\n",
        "    self.linear2 = nn.Linear(256, 128)\n",
        "  def forward(self, h):\n",
        "    h = self.linear1(h)\n",
        "    h = F.relu(h)\n",
        "    h = self.linear2(h)\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHkGMPdY7HU1"
      },
      "outputs": [],
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.norm = nn.LayerNorm(128)\n",
        "    self.linear = nn.Linear(128,128,bias=False)\n",
        "\n",
        "  def forward(self, graph, training=False):\n",
        "    h0 = graph.ndata['h']\n",
        "\n",
        "    graph.update_all(fn.copy_u('h', 'm'), fn.sum('m', 'u_'))\n",
        "    h = F.relu(self.linear(graph.ndata['u_'])) + h0\n",
        "    h = self.norm(h)\n",
        "\n",
        "    h = F.dropout(h, p=0.2, training = training)\n",
        "\n",
        "    graph.ndata['h'] = h\n",
        "    return graph\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naipPzsl-5_g"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self,num_layers=4, graph_nsize=58, graph_esize=6, readout='sum', input_size=199):\n",
        "    super().__init__()\n",
        "    ####\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding_node = nn.Linear(graph_nsize, 128, bias=False)\n",
        "    self.embedding_edge = nn.Linear(graph_esize, 128, bias=False)\n",
        "    self.readout = readout\n",
        "\n",
        "    self.mp_layers = nn.ModuleList()\n",
        "    for _ in range(self.num_layers):\n",
        "      mp_layer = None\n",
        "      mp_layer = GraphConvolution()\n",
        "      self.mp_layers.append(mp_layer)\n",
        "\n",
        "    self.linear_out = nn.Linear(128, 1, bias=False)\n",
        "    #####\n",
        "    self.fc1 = nn.Linear(input_size, 256)\n",
        "    self.bn1 = nn.LayerNorm(256)\n",
        "    self.dropout1 = nn.Dropout(0.2)\n",
        "    self.fc2 = nn.Linear(256, 512)\n",
        "    self.bn2 = nn.LayerNorm(512)\n",
        "    self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    self.fc3 = nn.Linear(1, 1024)\n",
        "    self.bn3 = nn.LayerNorm(1024)\n",
        "    self.dropout3 = nn.Dropout(0.2)\n",
        "    self.fc4 = nn.Linear(1024, 512)\n",
        "    self.bn4 = nn.LayerNorm(512)\n",
        "    self.dropout4 = nn.Dropout(0.2)\n",
        "    self.fc5 = nn.Linear(512, 256)\n",
        "    self.bn5 = nn.LayerNorm(256)\n",
        "    self.dropout5 = nn.Dropout(0.2)\n",
        "    self.fc6 = nn.Linear(256, 128)\n",
        "    self.bn6 = nn.LayerNorm(128)\n",
        "    self.dropout6 = nn.Dropout(0.2)\n",
        "    self.fc7 = nn.Linear(128, 1)\n",
        "  def forward(self, graph, feature, training=False):\n",
        "    h = self.embedding_node(graph.ndata['h'].float())\n",
        "    e_ij = self.embedding_edge(graph.edata['e_ij'].float())\n",
        "    graph.ndata['h'] = h\n",
        "    graph.edata['e_ij'] = e_ij\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      graph = self.mp_layers[i](graph)\n",
        "\n",
        "    x1 = dgl.readout_nodes(graph, 'h', op=self.readout)\n",
        "    x1 = self.linear_out(x1)\n",
        "\n",
        "    x2 = self.fc1(feature)\n",
        "    x2 = self.bn1(x2)\n",
        "    x2 = torch.relu(x2)\n",
        "    x2 = self.dropout1(x2)\n",
        "    x2 = torch.relu(self.bn2(self.fc2(x2)))\n",
        "    x2 = self.dropout2(x2)\n",
        "    x2 = x2.view(-1,1)\n",
        "\n",
        "    x = torch.cat((x1,x2), dim=0)\n",
        "    x = torch.relu(self.bn3(self.fc3(x)))\n",
        "    x = self.dropout3(x)\n",
        "    x = torch.relu(self.bn4(self.fc4(x)))\n",
        "    x = self.dropout4(x)\n",
        "    x = torch.relu(self.bn5(self.fc5(x)))\n",
        "    x = self.dropout5(x)\n",
        "    x = torch.relu(self.bn6(self.fc6(x)))\n",
        "    x = self.dropout6(x)\n",
        "    out = self.fc7(x)\n",
        "    return(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKZBdlpn_noU"
      },
      "outputs": [],
      "source": [
        "model = MyModel(num_layers=4, graph_nsize=graph_nsize, graph_esize=graph_esize, readout='sum',input_size=input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnOfW4nzRvVc"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1cPDmefW4ys"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, y_hat, y):\n",
        "        loss = torch.sqrt(self.mse(y_hat,y))\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_G7T4NQW9RN"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = RMSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlL5u76nRZ8I"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0\n",
        "  for feat, grap, label in train_hlm_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(graph=grap, feature=feat, training=True)\n",
        "\n",
        "    loss = criterion(outputs, label.view(-1, 1))\n",
        "    loss.backward()\n",
        "    running_loss += loss.item()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(running_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74D1zmEsbvfw"
      },
      "outputs": [],
      "source": [
        "math.sqrt(running_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXuVINiK6Gqm"
      },
      "outputs": [],
      "source": [
        "np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0Evl2X04lKk"
      },
      "outputs": [],
      "source": [
        "a.ndata['h'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDSXIkU433u4"
      },
      "outputs": [],
      "source": [
        "a.edata['e_ij'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlbPo5qvdVLa"
      },
      "outputs": [],
      "source": [
        "embedding_node = nn.Linear(58, 128)\n",
        "embedding_edge = nn.Linear(6, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPQoF0m34HB0"
      },
      "outputs": [],
      "source": [
        "n = a.ndata['h'].float()\n",
        "n = embedding_node(n)\n",
        "e = a.edata['e_ij'].float()\n",
        "e = embedding_edge(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rUs5vtV5Bko"
      },
      "outputs": [],
      "source": [
        "a.ndata['h'] = n\n",
        "a.edata['e_ij'] = e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJIHN-AR5O8f"
      },
      "outputs": [],
      "source": [
        "h0 = a.ndata['h']\n",
        "a.update_all(fn.copy_u('h', 'm'), fn.sum('m','u_'))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNAcnCij6Tzy"
      },
      "outputs": [],
      "source": [
        "lin = nn.Linear(128, 128)\n",
        "nrom = nn.LayerNorm(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6m_Hg2r6eFc"
      },
      "outputs": [],
      "source": [
        "h = F.relu(lin(a.ndata['u_'])) + h0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBqCkBOB60q6"
      },
      "outputs": [],
      "source": [
        "a.ndata['h'] = h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSmScdWr6xVG"
      },
      "outputs": [],
      "source": [
        "h = F.dropout(h, p=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khM4QTRJ7Yen"
      },
      "outputs": [],
      "source": [
        "dgl.readout_nodes(a, 'h', op='sum').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5Ky7n9L7h_R"
      },
      "outputs": [],
      "source": [
        "h.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUnBKlS54ivE"
      },
      "outputs": [],
      "source": [
        "d = torch.randn(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1oq51Oe_WH8"
      },
      "outputs": [],
      "source": [
        "d.view(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJZpTUNjVNZF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
