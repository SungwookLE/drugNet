{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#여기서 주의할 점은\n",
    "#SMOTE를 적용할 때는 반드시 학습 데이터 세트만 오버샘플링을 해야합니다!!!\n",
    "# 검증 데이터 세트 혹은 테스트 데이터 세트를 오버샘플링 하는 경우 결국 원본 데이터가 아닌 데이터 세트에서 검증되기 때문에 올바른 검증이 되지 않습니다. \n",
    "#https://coding-potato.tistory.com/17\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "\n",
    "from typing import List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morgan_binary_features_generator(mol: Union[str, Chem.Mol], plot_img = False,\n",
    "                                     radius: int = 6,\n",
    "                                     num_bits: int = 4096) -> np.ndarray:\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    if plot_img:\n",
    "        display(mol)\n",
    "    \n",
    "    features_vec = AllChem.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n",
    "    features = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMolDescriptors(mol: Union[str, Chem.Mol], missingVal=None):\n",
    "    ''' calculate the full list of descriptors for a molecule\n",
    "\n",
    "        missingVal is used if the descriptor cannot be calculated\n",
    "    '''\n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    res = {}\n",
    "    for nm,fn in Descriptors._descList:\n",
    "        # some of the descriptor fucntions can throw errors if they fail, catch those here:\n",
    "        try:\n",
    "            val = fn(mol)\n",
    "        except:\n",
    "            # print the error message:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # and set the descriptor value to whatever missingVal is\n",
    "            val = missingVal\n",
    "        res[nm] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=-1):\n",
    "        self.patience = patience  # number of times to allow for no improvement before stopping the execution\n",
    "        self.min_delta = min_delta  # the minimum change to be counted as improvement: if it is negative means, lower value is good\n",
    "        self.counter = 0  # count the number of times the validation accuracy not improving\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    # return True when encountering _patience_ times decrease in validation loss \n",
    "    def __call__(self, validation_loss, verbose=False):\n",
    "        if ((validation_loss+self.min_delta) < self.min_validation_loss):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0  # reset the counter if validation loss decreased at least by min_delta\n",
    "            \n",
    "        elif ((validation_loss+self.min_delta) > self.min_validation_loss):\n",
    "            self.counter += 1 # increase the counter if validation loss is not decreased by the min_delta\n",
    "            if verbose:\n",
    "                print(f\"  >> now{validation_loss:.3f} > best{self.min_validation_loss:.3f}\")\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "train_df.drop_duplicates([\"SMILES\"], inplace=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "train_descriptor = pd.DataFrame([getMolDescriptors(smile) for smile in train_df['SMILES']])\n",
    "test_descriptor =  pd.DataFrame([getMolDescriptors(smile) for smile in test_df['SMILES']])\n",
    "\n",
    "train_df = pd.concat([train_df, train_descriptor], axis=1)\n",
    "test_df = pd.concat([test_df, test_descriptor], axis=1)\n",
    "\n",
    "train_df.drop(columns=['MolWt', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'MolLogP'], axis=1, inplace=True)\n",
    "test_df.drop(columns=['MolWt', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'MolLogP'], axis=1, inplace=True)\n",
    "\n",
    "train_df.fillna(train_df.mean(numeric_only=True), inplace=True)\n",
    "test_df.fillna(test_df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "train_df=train_df.drop(train_df.loc[train_df[\"MLM\"]>100].index).reset_index(drop=True)\n",
    "train_df=train_df.drop(train_df.loc[train_df[\"HLM\"]>100].index).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_df[\"AlogP\"] = np.where(pd.isna(train_df[\"AlogP\"]), train_df[\"LogD\"], train_df[\"AlogP\"])\n",
    "test_df[\"AlogP\"] = np.where(pd.isna(test_df[\"AlogP\"]), test_df[\"LogD\"], test_df[\"AlogP\"])\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "train_MLM_x, train_MLM_y = smote.fit_resample(train_df.drop(columns=['id','SMILES', \"HLM\"]), train_df[\"MLM\"].apply(lambda x: np.int8(x//10)))\n",
    "train_HLM_x, train_HLM_y = smote.fit_resample(train_df.drop(columns=['id','SMILES', \"MLM\"]), train_df[\"HLM\"].apply(lambda x: np.int8(x//10)))\n",
    "\n",
    "train_MLM = TabularDataset(train_MLM_x)\n",
    "train_HLM = TabularDataset(train_HLM_x)\n",
    "test = TabularDataset(test_df.drop([\"id\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MLM_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_MLM = TabularPredictor(label='MLM', eval_metric='root_mean_squared_error', verbosity=False).fit(train_MLM)\n",
    "predictor_HLM = TabularPredictor(label='HLM', eval_metric='root_mean_squared_error', verbosity=False).fit(train_HLM)\n",
    "\n",
    "ld_board_MLM = predictor_MLM.leaderboard(train_MLM, silent=True)\n",
    "print(\"=\"*20, \"MLM\", \"=\"*20)\n",
    "print(ld_board_MLM)\n",
    "print(f\"Best: {predictor_MLM.get_model_best()}\")\n",
    "\n",
    "ld_board_HLM = predictor_HLM.leaderboard(train_HLM, silent=True)\n",
    "print(\"=\"*20, \"HLM\", \"=\"*20)\n",
    "print(ld_board_HLM)\n",
    "print(f\"Best: {predictor_HLM.get_model_best()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_png=predictor_MLM.plot_ensemble_model()\n",
    "display(Image(filename=path_to_png))\n",
    "path_to_png=predictor_HLM.plot_ensemble_model()\n",
    "display(Image(filename=path_to_png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과파일 작성\n",
    "pred_MLM = predictor_MLM.predict(test)\n",
    "pred_HLM = predictor_HLM.predict(test)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test_df[\"id\"]\n",
    "submission[\"MLM\"] = pred_MLM\n",
    "submission[\"HLM\"] = pred_HLM\n",
    "\n",
    "submission.to_csv(\"../output/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check before sub\n",
    "submission.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
